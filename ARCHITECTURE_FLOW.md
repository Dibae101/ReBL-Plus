# Multimodal Bug Reproduction Flow

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Bug Report File                          â”‚
â”‚  NewPipe_v0.20.11_enhanced.txt                             â”‚
â”‚                                                             â”‚
â”‚  [STEP 1] Open Chrome                                       â”‚
â”‚  [IMAGE:images/step1.png]  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚                                         â”‚                   â”‚
â”‚  [STEP 2] Search HTML examples          â”‚                   â”‚
â”‚  [IMAGE:images/step2.png]  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”               â”‚
â”‚                                         â”‚  â”‚                â”‚
â”‚  [STEP 3] Copy formatted text           â”‚  â”‚                â”‚
â”‚  [IMAGE:images/step3.png]  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚  â”‚  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
                    â–¼                       â”‚  â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚  â”‚
              â”‚  step1   â”‚                 â”‚  â”‚
              â”‚  .png    â”‚                 â”‚  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚  â”‚
                    â”‚                      â”‚  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ utils.py        â”‚
           â”‚ read_bug_report()â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Returns Dictionary:     â”‚
           â”‚  {                       â”‚
           â”‚    'text': "...",        â”‚
           â”‚    'images': [paths]     â”‚
           â”‚  }                       â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ reproduction.py â”‚
           â”‚ reproduce_bug() â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Add to history:         â”‚
           â”‚  {                       â”‚
           â”‚    "role": "user",       â”‚
           â”‚    "content": text,      â”‚
           â”‚    "images": [paths]     â”‚
           â”‚  }                       â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ my_gpt.py       â”‚
           â”‚ generate_text() â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ convert_history_to_multimodal()â”‚
    â”‚                                â”‚
    â”‚ 1. Extract text from history   â”‚
    â”‚ 2. Load images with PIL        â”‚
    â”‚ 3. Combine into contents[]     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Gemini API Content:     â”‚
    â”‚                         â”‚
    â”‚ ["User: Bug Report...", â”‚
    â”‚  PIL.Image(step1.png),  â”‚
    â”‚  PIL.Image(step2.png),  â”‚
    â”‚  PIL.Image(step3.png)]  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Gemini 2.5 Pro         â”‚
    â”‚  (Vision + Language)    â”‚
    â”‚                         â”‚
    â”‚  ğŸ§  Processes text       â”‚
    â”‚  ğŸ‘ï¸  Analyzes images     â”‚
    â”‚  ğŸ¤” Understands context  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Response:              â”‚
    â”‚                         â”‚
    â”‚  {"action": "click",    â”‚
    â”‚   "feature": "Chrome"}  â”‚
    â”‚                         â”‚
    â”‚  âœ… Now understands to   â”‚
    â”‚     open Chrome!        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Flow Comparison

### Without Images (OLD)
```
Bug Report Text
      â†“
  [reproduction.py]
      â†“
  history = [{"role": "user", "content": "Open browser..."}]
      â†“
  [my_gpt.py]
      â†“
  Gemini receives: "Open a web browser"
      â†“
  Gemini thinks: "What browser? Where? How?"
      â†“
  âŒ Skips step or fails
```

### With Images (NEW)
```
Bug Report Text + [IMAGE:...] markers
      â†“
  [utils.py] extracts images
      â†“
  {text: "...", images: [paths]}
      â†“
  [reproduction.py]
      â†“
  history = [{"role": "user", "content": "Open browser...", "images": [paths]}]
      â†“
  [my_gpt.py] loads images with PIL
      â†“
  Gemini receives: 
    - Text: "Open a web browser"
    - Image: [Screenshot showing Chrome icon]
      â†“
  Gemini thinks: "I see Chrome icon at position X,Y"
      â†“
  âœ… Clicks Chrome icon
```

## Example: Step-by-Step Execution

### Step 1: Bug Report Parsing
```python
# Input file: NewPipe_v0.20.11_enhanced.txt
"""
[STEP 1] Open Chrome
[IMAGE:images/newpipe_5912_step1.png]
"""

# After parsing
{
    'text': "Bug Report: [STEP 1] Open Chrome",
    'images': ['/absolute/path/to/images/newpipe_5912_step1.png']
}
```

### Step 2: History Creation
```python
history = [
    {"role": "system", "content": "You are a bug reproducer..."},
    {
        "role": "user",
        "content": "Bug Report: [STEP 1] Open Chrome",
        "images": ['/path/to/step1.png']
    }
]
```

### Step 3: Multimodal Conversion
```python
contents = [
    "System: You are a bug reproducer...",
    "User: Bug Report: [STEP 1] Open Chrome",
    PIL.Image.open('/path/to/step1.png')  # â† Image object
]
```

### Step 4: Gemini Processing
```
Input to Gemini:
- Text context about bug reproduction
- Visual: Screenshot showing phone home screen with Chrome icon
- Task: Figure out what to do

Gemini's Understanding:
- Text says: "Open Chrome"
- Image shows: Chrome icon at coordinates (X, Y)
- Action: click on Chrome icon

Output:
{"action": "click", "feature": "Chrome"}
```

## Why This Works Better

### Problem: "Copy formatted text from browser"

#### Without Images
```
LLM reads: "Copy formatted text from browser"

LLM doesn't know:
âŒ Which browser? (Chrome? Firefox? Safari?)
âŒ What is "formatted text"?
âŒ Where to find it?
âŒ How to identify it visually?

Result: Skips or fails
```

#### With Images
```
LLM reads: "Copy formatted text from browser"
LLM sees:
âœ… Image 1: Chrome icon on home screen
âœ… Image 2: Chrome opened with search
âœ… Image 3: Webpage with underlined text visible
âœ… Image 4: Text selection menu

LLM understands:
âœ… Open Chrome (saw the icon)
âœ… Search for example (saw search bar)
âœ… Find underlined text (saw it in image)
âœ… Copy it (saw selection menu)

Result: Successfully follows steps
```

## Performance Considerations

### Token Usage
```
Text-only:  ~4000 tokens
With 8 images:  ~4000 text + ~16000 image tokens = ~20000 total

Cost: Slightly higher but worth it for complex bugs
```

### Processing Time
```
Text-only:  2-3 seconds per response
Multimodal:  3-5 seconds per response (image encoding)

Tradeoff: Acceptable for better accuracy
```

## Success Metrics

### Expected Improvements

| Metric | Without Images | With Images |
|--------|---------------|-------------|
| Browser opened | âŒ 0% | âœ… Expected 80%+ |
| Correct app found | âŒ 10% | âœ… Expected 90%+ |
| Formatted text copied | âŒ 0% | âœ… Expected 70%+ |
| Bug reproduced | âŒ 0% | âœ… Expected 60%+ |

### How to Measure
1. Run 5 times with text-only â†’ Count successes
2. Run 5 times with images â†’ Count successes
3. Compare success rates

## File Dependencies

```
reproduction.py
    â”œâ”€â”€ imports utils.py
    â”‚       â””â”€â”€ read_bug_report()
    â”‚           â””â”€â”€ returns {text, images}
    â”‚
    â””â”€â”€ imports my_gpt.py
            â”œâ”€â”€ generate_text()
            â”‚   â”œâ”€â”€ convert_history_to_multimodal()
            â”‚   â””â”€â”€ PIL.Image.open()
            â”‚
            â””â”€â”€ genai.GenerativeModel()
                â””â”€â”€ Gemini 2.5 Pro API
```

## Testing Flow

```
1. Create/verify images exist
   â†“
2. Run test_multimodal.py
   â†“ (if pass)
3. Run reproduction.py with enhanced bug report
   â†“
4. Monitor console output for:
   - Image loading messages
   - LLM understanding of steps
   - Action decisions
   â†“
5. Compare with text-only version
   â†“
6. Iterate: Add more images or annotations if needed
```

## Debugging Checklist

- [ ] Images exist in `Automation/BRs/images/`
- [ ] Image paths in bug report match filenames
- [ ] Paths are relative: `images/file.png`
- [ ] Pillow installed: `pip show Pillow`
- [ ] Test passes: `python test_multimodal.py`
- [ ] Images load: Check console output
- [ ] Gemini API key valid
- [ ] Bug report format correct

## Next Steps

1. âœ… Setup complete (files created, images generated)
2. â³ Test with reproduction script
3. â³ Observe if LLM opens Chrome correctly
4. â³ Replace placeholders with real screenshots
5. â³ Apply to other bugs in your dataset
